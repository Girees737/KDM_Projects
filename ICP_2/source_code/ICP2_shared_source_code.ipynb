{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KDM_ICP2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dh8HjUuVdE9s"
      },
      "source": [
        "# Install stanza, Installing and importing Stanza are as simple as running the following commands. \r\n",
        "#!pip install stanza\r\n",
        "\r\n",
        "# Import stanza\r\n",
        "import stanza"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ly91QU2e5aCF",
        "outputId": "b857c7d9-5cfa-4889-90ab-22ec8feb2475"
      },
      "source": [
        "!pip install stanza"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting stanza\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/ae/a70a58ce6b4e2daad538688806ee0f238dbe601954582a74ea57cde6c532/stanza-1.2-py3-none-any.whl (282kB)\n",
            "\u001b[K     |████████████████████████████████| 286kB 5.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from stanza) (3.12.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from stanza) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from stanza) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from stanza) (2.23.0)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.6/dist-packages (from stanza) (1.7.0+cu101)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->stanza) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->stanza) (51.3.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (2.10)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.3.0->stanza) (0.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.3.0->stanza) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.3.0->stanza) (3.7.4.3)\n",
            "Installing collected packages: stanza\n",
            "Successfully installed stanza-1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwyQwpeYsFEj"
      },
      "source": [
        "Setting up Stanford CoreNLP\r\n",
        "\r\n",
        "In order for the interface to work, the Stanford CoreNLP library has to be installed and a CORENLP_HOME environment variable has to be pointed to the installation location.\r\n",
        "\r\n",
        "Here I am going to show you how to download and install the CoreNLP library on your machine, with Stanza's installation command:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNYFfu47dMDp",
        "outputId": "0fb62f0a-b47e-42de-e568-a6baaaf877be"
      },
      "source": [
        "# Download the Stanford CoreNLP package with Stanza's installation command\r\n",
        "# This'll take several minutes, depending on the network speed\r\n",
        "corenlp_dir = './corenlp'\r\n",
        "stanza.install_corenlp(dir=corenlp_dir)\r\n",
        "\r\n",
        "# Set the CORENLP_HOME environment variable to point to the installation location\r\n",
        "import os\r\n",
        "os.environ[\"CORENLP_HOME\"] = corenlp_dir"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-01-30 01:26:59 INFO: Installing CoreNLP package into ./corenlp...\n",
            "Downloading http://nlp.stanford.edu/software/stanford-corenlp-latest.zip: 100%|██████████| 505M/505M [00:16<00:00, 31.3MB/s]\n",
            "2021-01-30 01:27:18 WARNING: For customized installation location, please set the `CORENLP_HOME` environment variable to the location of the installation. In Unix, this is done with `export CORENLP_HOME=./corenlp`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cExj-I4QsYNu"
      },
      "source": [
        "That's all for the installation!\r\n",
        "\r\n",
        "We can now double check if the installation is successful by listing files in the CoreNLP directory. \r\n",
        "\r\n",
        "You should be able to see a number of .jar files by running the following command:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4k0OSQX9dl6v",
        "outputId": "09b464ec-9a57-4551-fe0f-a61c357dc69b"
      },
      "source": [
        "# Examine the CoreNLP installation folder to make sure the installation is successful\r\n",
        "!ls $CORENLP_HOME"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "build.xml\t\t\t\t  jollyday.jar\n",
            "corenlp.sh\t\t\t\t  LIBRARY-LICENSES\n",
            "CoreNLP-to-HTML.xsl\t\t\t  LICENSE.txt\n",
            "ejml-core-0.39.jar\t\t\t  Makefile\n",
            "ejml-core-0.39-sources.jar\t\t  patterns\n",
            "ejml-ddense-0.39.jar\t\t\t  pom-java-11.xml\n",
            "ejml-ddense-0.39-sources.jar\t\t  pom.xml\n",
            "ejml-simple-0.39.jar\t\t\t  protobuf.jar\n",
            "ejml-simple-0.39-sources.jar\t\t  README.txt\n",
            "input.txt\t\t\t\t  RESOURCE-LICENSES\n",
            "input.txt.out\t\t\t\t  SemgrexDemo.java\n",
            "input.txt.xml\t\t\t\t  ShiftReduceDemo.java\n",
            "javax.activation-api-1.2.0.jar\t\t  slf4j-api.jar\n",
            "javax.activation-api-1.2.0-sources.jar\t  slf4j-simple.jar\n",
            "javax.json-api-1.0-sources.jar\t\t  stanford-corenlp-4.2.0.jar\n",
            "javax.json.jar\t\t\t\t  stanford-corenlp-4.2.0-javadoc.jar\n",
            "jaxb-api-2.4.0-b180830.0359.jar\t\t  stanford-corenlp-4.2.0-models.jar\n",
            "jaxb-api-2.4.0-b180830.0359-sources.jar   stanford-corenlp-4.2.0-sources.jar\n",
            "jaxb-core-2.3.0.1.jar\t\t\t  StanfordCoreNlpDemo.java\n",
            "jaxb-core-2.3.0.1-sources.jar\t\t  StanfordDependenciesManual.pdf\n",
            "jaxb-impl-2.4.0-b180830.0438.jar\t  sutime\n",
            "jaxb-impl-2.4.0-b180830.0438-sources.jar  tokensregex\n",
            "joda-time-2.10.5-sources.jar\t\t  xom-1.3.2-sources.jar\n",
            "joda-time.jar\t\t\t\t  xom.jar\n",
            "jollyday-0.4.9-sources.jar\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmp2gc4Gsm_Q"
      },
      "source": [
        "Constructing CoreNLPClient\r\n",
        "\r\n",
        "At a high level, the CoreNLP Python interface works by first starting a background Java CoreNLP server process, and then initializing a client instance in Python which can pass the text to the background server process, and accept the returned annotation results.\r\n",
        "\r\n",
        "We wrap these functionalities in a CoreNLPClient class. Therefore, we need to start by importing this class from Stanza."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQaXGcIidp8N"
      },
      "source": [
        "# Import client module\r\n",
        "from stanza.server import CoreNLPClient"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ly99wQ9sswl1"
      },
      "source": [
        "After the import is done, we can construct a CoreNLPClient instance. The constructor method takes a Python list of annotator names as argument. Here let's explore some basic annotators including tokenization, sentence split, part-of-speech tagging, lemmatization, named entity recognition (NER), parsing and Coreference resolution. \r\n",
        "\r\n",
        "Additionally, the client constructor accepts a memory argument, which specifies how much memory will be allocated to the background Java process. An endpoint option can be used to specify a port number used by the communication between the server and the client. The default port is 9000. However, since this port is pre-occupied by a system process in Colab, we'll manually set it to 9001 in the following example.\r\n",
        "\r\n",
        "Also, here we manually set be_quiet=True to avoid an IO issue in colab notebook. You should be able to use be_quiet=False on your own computer, which will print detailed logging information from CoreNLP during usage.\r\n",
        "\r\n",
        "For more options in constructing the clients, please refer to 'https://stanfordnlp.github.io/stanza/corenlp_client.html#corenlp-client-options'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXez1IpIdxYF",
        "outputId": "a7e8149a-67dc-4660-ca31-03b1a690cc74"
      },
      "source": [
        "# Construct a CoreNLPClient with some basic annotators, a memory allocation of 4GB, and port number 9001\r\n",
        "client = CoreNLPClient(\r\n",
        "    annotators=['tokenize','ssplit','pos','lemma','ner', 'parse', 'depparse','coref'], \r\n",
        "    memory='4G', \r\n",
        "    endpoint='http://localhost:9001',\r\n",
        "    be_quiet=True)\r\n",
        "print(client)\r\n",
        "\r\n",
        "# Start the background server and wait for some time\r\n",
        "# Note that in practice this is totally optional, as by default the server will be started when the first annotation is performed\r\n",
        "client.start()\r\n",
        "import time; time.sleep(10)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-01-30 01:27:50 INFO: Writing properties to tmp file: corenlp_server-78ab13060ba34c62.props\n",
            "2021-01-30 01:27:50 INFO: Starting server with command: java -Xmx4G -cp ./corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 60000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-78ab13060ba34c62.props -annotators tokenize,ssplit,pos,lemma,ner,parse,depparse,coref -preload -outputFormat serialized\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<stanza.server.client.CoreNLPClient object at 0x7f4c6cc61048>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huHe7t4NttN6"
      },
      "source": [
        "After the above code block finishes executing, if you print the background processes, you should be able to find the Java CoreNLP server running."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-6a5KoAd-H2",
        "outputId": "4f69790f-d09b-4684-af74-d05476eec7ac"
      },
      "source": [
        "# Print background processes and look for java\r\n",
        "# You should be able to see a StanfordCoreNLPServer java process running in the background\r\n",
        "!ps -o pid,cmd | grep java"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    112 java -Xmx4G -cp ./corenlp/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9001 -timeout 60000 -threads 5 -maxCharLength 100000 -quiet True -serverProperties corenlp_server-78ab13060ba34c62.props -annotators tokenize,ssplit,pos,lemma,ner,parse,depparse,coref -preload -outputFormat serialized\n",
            "    135 /bin/bash -c ps -o pid,cmd | grep java\n",
            "    137 grep java\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YgEdpIgtxt9"
      },
      "source": [
        "Annotating Text\r\n",
        "\r\n",
        "Annotating a piece of text is as simple as passing the text into an annotate function of the client object. After the annotation is complete, a Document object will be returned with all annotations.\r\n",
        "\r\n",
        "Note that although in general annotations are very fast, the first annotation might take a while to complete in the notebook. Please stay patient."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IT3DqBv-eDrl",
        "outputId": "0da63a5a-5097-4d11-ea48-361a395e9748"
      },
      "source": [
        "# Annotate some text\r\n",
        "text = \"Albert Einstein was a German-born theoretical physicist. He developed the theory of relativity.\"\r\n",
        "document = client.annotate(text)\r\n",
        "print(type(document))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'CoreNLP_pb2.Document'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U43zcqcTuHV4"
      },
      "source": [
        "Accessing Annotations\r\n",
        "\r\n",
        "Annotations can be accessed from the returned Document object.\r\n",
        "\r\n",
        "A Document contains a list of Sentences, which contain a list of Tokens. Here let's first explore the annotations stored in all tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gLDG2Ihe6yr",
        "outputId": "d74b31a8-cb3e-462e-8de2-38b8ec33a1aa"
      },
      "source": [
        "print(\"{:12s}\\t{:12s}\\t{:6s}\\t{}\".format(\"Word\", \"Lemma\", \"POS\", \"NER\"))\r\n",
        "\r\n",
        "for i, sent in enumerate(document.sentence):\r\n",
        "    print(\"[Sentence {}]\".format(i+1))\r\n",
        "    for t in sent.token:\r\n",
        "        print(\"{:12s}\\t{:12s}\\t{:6s}\\t{}\".format(t.word, t.lemma, t.pos, t.ner))\r\n",
        "    print(\"\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word        \tLemma       \tPOS   \tNER\n",
            "[Sentence 1]\n",
            "Albert      \tAlbert      \tNNP   \tPERSON\n",
            "Einstein    \tEinstein    \tNNP   \tPERSON\n",
            "was         \tbe          \tVBD   \tO\n",
            "a           \ta           \tDT    \tO\n",
            "German      \tgerman      \tJJ    \tNATIONALITY\n",
            "-           \t-           \tHYPH  \tO\n",
            "born        \tbear        \tVBN   \tO\n",
            "theoretical \ttheoretical \tJJ    \tTITLE\n",
            "physicist   \tphysicist   \tNN    \tTITLE\n",
            ".           \t.           \t.     \tO\n",
            "\n",
            "[Sentence 2]\n",
            "He          \the          \tPRP   \tO\n",
            "developed   \tdevelop     \tVBD   \tO\n",
            "the         \tthe         \tDT    \tO\n",
            "theory      \ttheory      \tNN    \tO\n",
            "of          \tof          \tIN    \tO\n",
            "relativity  \trelativity  \tNN    \tO\n",
            ".           \t.           \t.     \tO\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzs40nFOurmP"
      },
      "source": [
        "Alternatively, you can also browse the NER results by iterating over entity mentions over the sentences. For example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-k16JaXWuL9U",
        "outputId": "797344b0-e5d1-4510-d1a7-11640f5eb3fb"
      },
      "source": [
        "# Iterate over all detected entity mentions\r\n",
        "print(\"{:30s}\\t{}\".format(\"Mention\", \"Type\"))\r\n",
        "\r\n",
        "for sent in document.sentence:\r\n",
        "    for m in sent.mentions:\r\n",
        "        print(\"{:30s}\\t{}\".format(m.entityMentionText, m.entityType))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mention                       \tType\n",
            "Albert Einstein               \tPERSON\n",
            "German                        \tNATIONALITY\n",
            "theoretical physicist         \tTITLE\n",
            "He                            \tPERSON\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLF2wlNkuulf"
      },
      "source": [
        "To print all annotations a sentence, token or mention has, you can simply print the corresponding obejct."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fn8xLrYaubAu",
        "outputId": "3f5d860a-2e83-4b01-980f-74ff67d3ea1b"
      },
      "source": [
        "# Print annotations of a token\r\n",
        "print(document.sentence[0].token[0])\r\n",
        "\r\n",
        "# Print annotations of a mention\r\n",
        "print(document.sentence[0].mentions[0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "word: \"Albert\"\n",
            "pos: \"NNP\"\n",
            "value: \"Albert\"\n",
            "before: \"\"\n",
            "after: \" \"\n",
            "originalText: \"Albert\"\n",
            "ner: \"PERSON\"\n",
            "lemma: \"Albert\"\n",
            "beginChar: 0\n",
            "endChar: 6\n",
            "utterance: 0\n",
            "speaker: \"PER0\"\n",
            "beginIndex: 0\n",
            "endIndex: 1\n",
            "tokenBeginIndex: 0\n",
            "tokenEndIndex: 1\n",
            "hasXmlContext: false\n",
            "isNewline: false\n",
            "coarseNER: \"PERSON\"\n",
            "fineGrainedNER: \"PERSON\"\n",
            "corefMentionIndex: 0\n",
            "entityMentionIndex: 0\n",
            "nerLabelProbs: \"PERSON=0.9999331283889166\"\n",
            "\n",
            "sentenceIndex: 0\n",
            "tokenStartInSentenceInclusive: 0\n",
            "tokenEndInSentenceExclusive: 2\n",
            "ner: \"PERSON\"\n",
            "entityType: \"PERSON\"\n",
            "entityMentionIndex: 0\n",
            "canonicalEntityMentionIndex: 0\n",
            "entityMentionText: \"Albert Einstein\"\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zy9-S9MOihzI",
        "outputId": "5981ec8c-0f33-4e99-eba5-ce5d50c31aa8"
      },
      "source": [
        "  # get the first sentence\r\n",
        "sentence = document.sentence[0]\r\n",
        "    \r\n",
        "# get the constituency parse of the first sentence\r\n",
        "print('---')\r\n",
        "print('constituency parse of first sentence')\r\n",
        "constituency_parse = sentence.parseTree\r\n",
        "print(constituency_parse)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---\n",
            "constituency parse of first sentence\n",
            "child {\n",
            "  child {\n",
            "    child {\n",
            "      child {\n",
            "        value: \"Albert\"\n",
            "      }\n",
            "      value: \"NNP\"\n",
            "      score: -8.849637985229492\n",
            "    }\n",
            "    child {\n",
            "      child {\n",
            "        value: \"Einstein\"\n",
            "      }\n",
            "      value: \"NNP\"\n",
            "      score: -10.39391803741455\n",
            "    }\n",
            "    value: \"NP\"\n",
            "    score: -22.208171844482422\n",
            "  }\n",
            "  child {\n",
            "    child {\n",
            "      child {\n",
            "        value: \"was\"\n",
            "      }\n",
            "      value: \"VBD\"\n",
            "      score: -0.42985981702804565\n",
            "    }\n",
            "    child {\n",
            "      child {\n",
            "        child {\n",
            "          value: \"a\"\n",
            "        }\n",
            "        value: \"DT\"\n",
            "        score: -1.5601264238357544\n",
            "      }\n",
            "      child {\n",
            "        child {\n",
            "          child {\n",
            "            value: \"German\"\n",
            "          }\n",
            "          value: \"JJ\"\n",
            "          score: -5.692482948303223\n",
            "        }\n",
            "        child {\n",
            "          child {\n",
            "            value: \"-\"\n",
            "          }\n",
            "          value: \"HYPH\"\n",
            "          score: -0.01210630964487791\n",
            "        }\n",
            "        child {\n",
            "          child {\n",
            "            value: \"born\"\n",
            "          }\n",
            "          value: \"VBN\"\n",
            "          score: -5.775586128234863\n",
            "        }\n",
            "        value: \"ADJP\"\n",
            "        score: -15.493135452270508\n",
            "      }\n",
            "      child {\n",
            "        child {\n",
            "          value: \"theoretical\"\n",
            "        }\n",
            "        value: \"JJ\"\n",
            "        score: -9.2328519821167\n",
            "      }\n",
            "      child {\n",
            "        child {\n",
            "          value: \"physicist\"\n",
            "        }\n",
            "        value: \"NN\"\n",
            "        score: -11.6840181350708\n",
            "      }\n",
            "      value: \"NP\"\n",
            "      score: -43.543113708496094\n",
            "    }\n",
            "    value: \"VP\"\n",
            "    score: -51.38176727294922\n",
            "  }\n",
            "  child {\n",
            "    child {\n",
            "      value: \".\"\n",
            "    }\n",
            "    value: \".\"\n",
            "    score: -0.05752464756369591\n",
            "  }\n",
            "  value: \"S\"\n",
            "  score: -74.78398132324219\n",
            "}\n",
            "value: \"ROOT\"\n",
            "score: -74.95536041259766\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Vcwv9sIlwZb",
        "outputId": "01b8087b-bb41-42be-807f-af2b278fbeb0"
      },
      "source": [
        " # get the first subtree of the constituency parse\r\n",
        "print('first subtree of constituency parse')\r\n",
        "print(constituency_parse.child[0])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "first subtree of constituency parse\n",
            "child {\n",
            "  child {\n",
            "    child {\n",
            "      value: \"Albert\"\n",
            "    }\n",
            "    value: \"NNP\"\n",
            "    score: -8.849637985229492\n",
            "  }\n",
            "  child {\n",
            "    child {\n",
            "      value: \"Einstein\"\n",
            "    }\n",
            "    value: \"NNP\"\n",
            "    score: -10.39391803741455\n",
            "  }\n",
            "  value: \"NP\"\n",
            "  score: -22.208171844482422\n",
            "}\n",
            "child {\n",
            "  child {\n",
            "    child {\n",
            "      value: \"was\"\n",
            "    }\n",
            "    value: \"VBD\"\n",
            "    score: -0.42985981702804565\n",
            "  }\n",
            "  child {\n",
            "    child {\n",
            "      child {\n",
            "        value: \"a\"\n",
            "      }\n",
            "      value: \"DT\"\n",
            "      score: -1.5601264238357544\n",
            "    }\n",
            "    child {\n",
            "      child {\n",
            "        child {\n",
            "          value: \"German\"\n",
            "        }\n",
            "        value: \"JJ\"\n",
            "        score: -5.692482948303223\n",
            "      }\n",
            "      child {\n",
            "        child {\n",
            "          value: \"-\"\n",
            "        }\n",
            "        value: \"HYPH\"\n",
            "        score: -0.01210630964487791\n",
            "      }\n",
            "      child {\n",
            "        child {\n",
            "          value: \"born\"\n",
            "        }\n",
            "        value: \"VBN\"\n",
            "        score: -5.775586128234863\n",
            "      }\n",
            "      value: \"ADJP\"\n",
            "      score: -15.493135452270508\n",
            "    }\n",
            "    child {\n",
            "      child {\n",
            "        value: \"theoretical\"\n",
            "      }\n",
            "      value: \"JJ\"\n",
            "      score: -9.2328519821167\n",
            "    }\n",
            "    child {\n",
            "      child {\n",
            "        value: \"physicist\"\n",
            "      }\n",
            "      value: \"NN\"\n",
            "      score: -11.6840181350708\n",
            "    }\n",
            "    value: \"NP\"\n",
            "    score: -43.543113708496094\n",
            "  }\n",
            "  value: \"VP\"\n",
            "  score: -51.38176727294922\n",
            "}\n",
            "child {\n",
            "  child {\n",
            "    value: \".\"\n",
            "  }\n",
            "  value: \".\"\n",
            "  score: -0.05752464756369591\n",
            "}\n",
            "value: \"S\"\n",
            "score: -74.78398132324219\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FM_DsQWZmnZL",
        "outputId": "8b911295-1799-4fff-9aa7-079528ca1a4f"
      },
      "source": [
        "# get the value of the first subtree\r\n",
        "print('---')\r\n",
        "print('value of first subtree of constituency parse')\r\n",
        "print(constituency_parse.child[0].value)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---\n",
            "value of first subtree of constituency parse\n",
            "S\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSTZso4OnONp",
        "outputId": "4a9d615b-15a8-476d-e0fe-7cead3c8f36f"
      },
      "source": [
        "  # get the first token of the first sentence\r\n",
        "  print('first token of first sentence')\r\n",
        "  token = sentence.token[0]\r\n",
        "  print(token)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "first token of first sentence\n",
            "word: \"Albert\"\n",
            "pos: \"NNP\"\n",
            "value: \"Albert\"\n",
            "before: \"\"\n",
            "after: \" \"\n",
            "originalText: \"Albert\"\n",
            "ner: \"PERSON\"\n",
            "lemma: \"Albert\"\n",
            "beginChar: 0\n",
            "endChar: 6\n",
            "utterance: 0\n",
            "speaker: \"PER0\"\n",
            "beginIndex: 0\n",
            "endIndex: 1\n",
            "tokenBeginIndex: 0\n",
            "tokenEndIndex: 1\n",
            "hasXmlContext: false\n",
            "isNewline: false\n",
            "coarseNER: \"PERSON\"\n",
            "fineGrainedNER: \"PERSON\"\n",
            "corefMentionIndex: 0\n",
            "entityMentionIndex: 0\n",
            "nerLabelProbs: \"PERSON=0.9999331283889166\"\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lv4zz0FuoGQz",
        "outputId": "faeec237-bee7-49d3-8aee-916c72812672"
      },
      "source": [
        "  # get the part-of-speech tag\r\n",
        "\r\n",
        "  print('part of speech tag of token')\r\n",
        "  token.pos\r\n",
        "  print(token.pos)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "part of speech tag of token\n",
            "NNP\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zW-vv45loTRO",
        "outputId": "fd0126a3-111a-489d-bae2-58cffc88258a"
      },
      "source": [
        "# get the named entity tag\r\n",
        "print('named entity tag of token')\r\n",
        "print(token.ner)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "named entity tag of token\n",
            "PERSON\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aItouLkmodwk",
        "outputId": "e76ce79c-b049-4d6a-a0e4-24fcad61ad07"
      },
      "source": [
        "# get an entity mention from the first sentence\r\n",
        "print('first entity mention in sentence')\r\n",
        "print(sentence.mentions[0])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "first entity mention in sentence\n",
            "sentenceIndex: 0\n",
            "tokenStartInSentenceInclusive: 0\n",
            "tokenEndInSentenceExclusive: 2\n",
            "ner: \"PERSON\"\n",
            "entityType: \"PERSON\"\n",
            "entityMentionIndex: 0\n",
            "canonicalEntityMentionIndex: 0\n",
            "entityMentionText: \"Albert Einstein\"\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjMw32LuouwD",
        "outputId": "87c7abc7-e3e0-49b0-d7e9-cc908fc5e86f"
      },
      "source": [
        " # access the coref chain\r\n",
        "print('coref chains for the example')\r\n",
        "print(document.corefChain)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "coref chains for the example\n",
            "[chainID: 4\n",
            "mention {\n",
            "  mentionID: 0\n",
            "  mentionType: \"PROPER\"\n",
            "  number: \"SINGULAR\"\n",
            "  gender: \"MALE\"\n",
            "  animacy: \"ANIMATE\"\n",
            "  beginIndex: 0\n",
            "  endIndex: 2\n",
            "  headIndex: 1\n",
            "  sentenceIndex: 0\n",
            "  position: 1\n",
            "}\n",
            "mention {\n",
            "  mentionID: 4\n",
            "  mentionType: \"PRONOMINAL\"\n",
            "  number: \"SINGULAR\"\n",
            "  gender: \"MALE\"\n",
            "  animacy: \"ANIMATE\"\n",
            "  beginIndex: 0\n",
            "  endIndex: 1\n",
            "  headIndex: 0\n",
            "  sentenceIndex: 1\n",
            "  position: 3\n",
            "}\n",
            "representative: 0\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "at9GdgxQrdub",
        "outputId": "00d2e5cc-c5b9-4468-e079-828968f279d8"
      },
      "source": [
        "mychains = list()\r\n",
        "chains = document.corefChain\r\n",
        "for chain in chains:\r\n",
        "    mychain = list()\r\n",
        "    # Loop through every mention of this chain\r\n",
        "    for mention in chain.mention:\r\n",
        "        # Get the sentence in which this mention is located, and get the words which are part of this mention\r\n",
        "        # (we can have more than one word, for example, a mention can be a pronoun like \"he\", but also a compound noun like \"His wife Michelle\")\r\n",
        "        words_list = document.sentence[mention.sentenceIndex].token[mention.beginIndex:mention.endIndex]\r\n",
        "        #build a string out of the words of this mention\r\n",
        "        ment_word = ' '.join([x.word for x in words_list])\r\n",
        "        mychain.append(ment_word)\r\n",
        "    mychains.append(mychain)\r\n",
        "\r\n",
        "for chain in mychains:\r\n",
        "    print(' <-> '.join(chain))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Albert Einstein <-> He\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45psltbBu9qq"
      },
      "source": [
        "Shutting Down the CoreNLP Server\r\n",
        "\r\n",
        "To shut down the background CoreNLP server process, simply call the stop function of the client. Note that once a server is shutdown, you'll have to restart the server with the start() function before any annotation is requested."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e8SN2AAgYY6",
        "outputId": "ba810deb-bf27-4a34-8320-3544abca05ee"
      },
      "source": [
        "# Shut down the background CoreNLP server\r\n",
        "client.stop()\r\n",
        "\r\n",
        "time.sleep(10)\r\n",
        "!ps -o pid,cmd | grep java"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    192 /bin/bash -c ps -o pid,cmd | grep java\n",
            "    194 grep java\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}