{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import bs4\n",
    "import requests\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "from spacy.matcher import Matcher \n",
    "from spacy.tokens import Span \n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='C:\\\\Users\\\\muppa\\\\OneDrive\\\\Desktop\\\\Entertainment.txt'\n",
    "path1='C:\\\\Users\\\\muppa\\\\OneDrive\\\\Desktop\\\\Sports.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path,'r',encoding='utf-8') as f:\n",
    "    entertainment_text=f.read()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path1,'r',encoding='utf-8') as f:\n",
    "    Sports_text=f.read()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tokenizing the sentences\n",
    "import nltk\n",
    "entertainment_text_list = nltk.tokenize.sent_tokenize(entertainment_text)\n",
    "sports_text_list = nltk.tokenize.sent_tokenize(Sports_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Roll out the (virtual) red carpet!',\n",
       " 'The 78th annual Golden Globe Awards might look a little different than previous years due to the coronavirus pandemic, but the night won’t be short of major stars.',\n",
       " 'NBC Entertainment announced in January 2020 that Amy Poehler and Tina Fey would be returning to host the awards show in 2021 after previously teaming up for the gig in 2013, 2014 and 2015.',\n",
       " '“NBC has long been the home to two of the funniest people on the planet — Tina Fey and Amy Poehler — and we didn’t want to wait any longer to share the great news that they’ll be hosting the Globes once again,” NBC Entertainment Chairman Paul Telegdy said in a statement to Us Weekly at the time, praising the former Saturday Night Live costars, who “have provided Golden Globes viewers with some of the most memorable moments the show has ever seen.”\\n\\nTwo months later, the COVID-19 crisis caused Hollywood to press pause.',\n",
       " 'While the entertainment industry was forced to adapt to a new normal of face masks and social distancing, the global pandemic didn’t keep the Hollywood Foreign Press Association from honoring some of the year’s best performances.',\n",
       " 'Nominations were officially announced on February 3, with Netflix’s Mank and The Crown tied for the most nods in film and TV categories, respectively.',\n",
       " 'While some nominees were total shoo-ins — like Hugh Grant in The Undoing and Viola Davis in Ma Rainey’s Black Bottom — others took fans by surprise.',\n",
       " 'When Michaela Coel’s I May Destroy You was overlooked in favor of Lily Collins’ Emily in Paris, awards show devotees weren’t afraid to call out the major snub on social media.',\n",
       " 'Despite facing backlash from TV lovers, Collins was proud of the Netflix series’ big achievements.',\n",
       " 'Along with her Best Television Actress – Musical/Comedy Series nomination, the Darren Star-created show earned a nod for Best Musical/Comedy Series.',\n",
       " '“Words cannot express how extremely grateful and excited I am to be nominated for my role in Emily in Paris and for the show’s nomination,” the To the Bone actress said in a statement to Us after earning the second Golden Globe nomination of her career.',\n",
       " '“I’m beyond thrilled the series was recognized and I feel so lucky to be in a category including such incredible women who have kept me laughing and smiling all year long.',\n",
       " 'The greatest gift of playing Emily has been providing a sense of escapism and fun during a time when we all needed it most.”\\n\\nScroll down for all the details on this year’s Golden Globes, from how to watch to who’s being honored']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entertainment_text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample sentences\n",
    "candidate_sentences = \"the drawdown process is governed by astm standard d823\"\n",
    "doc = nlp(candidate_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the ... det\n",
      "drawdown ... amod\n",
      "process ... nsubjpass\n",
      "is ... auxpass\n",
      "governed ... ROOT\n",
      "by ... agent\n",
      "astm ... compound\n",
      "standard ... amod\n",
      "d823 ... pobj\n"
     ]
    }
   ],
   "source": [
    "for tok in doc:\n",
    "    print(tok.text, \"...\", tok.dep_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entity Pairs Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entities(sent):\n",
    "  ## chunk 1\n",
    "  ent1 = \"\"\n",
    "  ent2 = \"\"\n",
    "\n",
    "  prv_tok_dep = \"\"    # dependency tag of previous token in the sentence\n",
    "  prv_tok_text = \"\"   # previous token in the sentence\n",
    "\n",
    "  prefix = \"\"\n",
    "  modifier = \"\"\n",
    "\n",
    "  #############################################################\n",
    "  \n",
    "  for tok in nlp(sent):\n",
    "    ## chunk 2\n",
    "    # if token is a punctuation mark then move on to the next token\n",
    "    if tok.dep_ != \"punct\":\n",
    "      # check: token is a compound word or not\n",
    "      if tok.dep_ == \"compound\":\n",
    "        prefix = tok.text\n",
    "        # if the previous word was also a 'compound' then add the current word to it\n",
    "        if prv_tok_dep == \"compound\":\n",
    "          prefix = prv_tok_text + \" \"+ tok.text\n",
    "      \n",
    "      # check: token is a modifier or not\n",
    "      if tok.dep_.endswith(\"mod\") == True:\n",
    "        modifier = tok.text\n",
    "        # if the previous word was also a 'compound' then add the current word to it\n",
    "        if prv_tok_dep == \"compound\":\n",
    "          modifier = prv_tok_text + \" \"+ tok.text\n",
    "      \n",
    "      ## chunk 3\n",
    "      if tok.dep_.find(\"subj\") == True:\n",
    "        ent1 = modifier +\" \"+ prefix + \" \"+ tok.text\n",
    "        prefix = \"\"\n",
    "        modifier = \"\"\n",
    "        prv_tok_dep = \"\"\n",
    "        prv_tok_text = \"\"      \n",
    "\n",
    "      ## chunk 4\n",
    "      if tok.dep_.find(\"obj\") == True:\n",
    "        ent2 = modifier +\" \"+ prefix +\" \"+ tok.text\n",
    "        \n",
    "      ## chunk 5  \n",
    "      # update variables\n",
    "      prv_tok_dep = tok.dep_\n",
    "      prv_tok_text = tok.text\n",
    "  #############################################################\n",
    "\n",
    "  return [ent1.strip(), ent2.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['film', '200  patents']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_entities(\"the film had 200 patents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entity Relation Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relation(sent):\n",
    "\n",
    "  doc = nlp(sent)\n",
    "\n",
    "  # Matcher class object \n",
    "  matcher = Matcher(nlp.vocab)\n",
    "\n",
    "  #define the pattern \n",
    "  pattern = [{'DEP':'ROOT'}, \n",
    "            {'DEP':'prep','OP':\"?\"},\n",
    "            {'DEP':'agent','OP':\"?\"},  \n",
    "            {'POS':'ADJ','OP':\"?\"}] \n",
    "\n",
    "  matcher.add(\"matching_1\", None, pattern) \n",
    "\n",
    "  matches = matcher(doc)\n",
    "  k = len(matches) - 1\n",
    "\n",
    "  span = doc[matches[k][1]:matches[k][2]] \n",
    "\n",
    "  return(span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'completed'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_relation(\"John completed the task\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining above both for triplets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"John completed the task\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent=get_entities(text)\n",
    "rel=get_relation(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['John', 'task']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['John', 'completed', 'task']\n"
     ]
    }
   ],
   "source": [
    "new_list=[]\n",
    "if len(ent)==2:\n",
    "    for i,n in enumerate(ent):\n",
    "        #print(i,n)\n",
    "        if i==1:\n",
    "            new_list.append(rel) \n",
    "        else:\n",
    "            new_list.append(n)\n",
    "    new_list.append(ent[1])\n",
    "print(new_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example:2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplets(text):\n",
    "# text=\"the drawdown process is governed by astm standard d823\"\n",
    "    ent=get_entities(text)\n",
    "    print(ent)\n",
    "    rel=get_relation(text)\n",
    "    print(rel)\n",
    "    new_list=[]\n",
    "    if len(ent)==2:\n",
    "        for i,n in enumerate(ent):\n",
    "            #print(i,n)\n",
    "            if i==1:\n",
    "                new_list.append(rel) \n",
    "            else:\n",
    "                new_list.append(n)\n",
    "        new_list.append(ent[1])\n",
    "        print(new_list)\n",
    "    return new_list\n",
    "# print(new_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
